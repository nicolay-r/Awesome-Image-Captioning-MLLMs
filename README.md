# Awesome-Image-Captioning-MLLMs
> **NOTE:** A curated list of awesome Image captioning strudies, aimed at annotating and reporting *CT / MRI scans*

## Focus of the Studies and Limitation üéØ

In the era since the announcement of the self-attention mechanism, the [Transformers architecture](https://arxiv.org/pdf/1706.03762v1.pdf) has become a game-chaning architecture in the field of machine-translation.
These findings and advances were quicly mitigated onto other fields in natural language processing (NLP) is when we end up with *Language Models* [[encoder-based]](https://aclanthology.org/N19-1423.pdf) and [[generative]](https://arxiv.org/pdf/2005.14165.pdf) we aware of so far.
This repository represent a collection of the systems and findids that may help you to advance yourself in development of Multimodal Large Language Models (MLLMs), that support the following modalities:
1. üñºÔ∏è **Image** (Photo, Scans, even Footages / Video frames gathered into sigle image)
2. üìù **Text** (Caption / Report / Question)

# Systems

* **Ferret-V2** (11 April, 2024) [[report]](https://arxiv.org/pdf/2404.07973.pdf)
* **OmniFusion** (09 April, 2024) [[report]](https://arxiv.org/pdf/2404.06212.pdf) [[code]](https://github.com/AIRI-Institute/OmniFusion)
* **MM1** (22 March, 2024) [report](https://arxiv.org/pdf/2403.09611.pdf)

## Encoders

* CLIP
* DINO-v2

# Related Lists

* [Awesome-CLIP-in-Medical-Imaging](https://github.com/zhaozh10/Awesome-CLIP-in-Medical-Imaging)
* [MLLM-thread @ huggingface](https://huggingface.co/collections/flow2023/mllm-6596190672376a9c3197ae36)
